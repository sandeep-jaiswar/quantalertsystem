name: Continuous Integration

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHONPATH: ${{ github.workspace }}

jobs:
  test-matrix:
    name: Test Suite (Python ${{ matrix.python-version }} on ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
        exclude:
          # Skip some combinations to reduce CI time
          - os: windows-latest
            python-version: '3.8'
          - os: macos-latest
            python-version: '3.8'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install coverage

    - name: Create test directories
      run: |
        mkdir -p logs data reports

    - name: Run unit tests with coverage
      env:
        TELEGRAM_BOT_TOKEN: "test_token_for_ci"
        TELEGRAM_CHAT_ID: "test_chat_id_for_ci"
        DATABASE_PATH: "./data/test_quant_alerts.db"
        LOG_LEVEL: "DEBUG"
      run: |
        PYTHONPATH=${{ github.workspace }} pytest tests/ \
          --cov=. \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term \
          --junit-xml=reports/junit.xml \
          -v --tb=short -m "not performance"

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-${{ matrix.os }}-${{ matrix.python-version }}

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          reports/
          htmlcov/
        retention-days: 30

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test-matrix]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create test environment
      run: |
        mkdir -p logs data

    - name: Run integration tests
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        DATABASE_PATH: "./data/integration_test.db"
        LOG_LEVEL: "INFO"
      run: |
        PYTHONPATH=${{ github.workspace }} pytest tests/integration/ -v --tb=short -m "integration"

    - name: Test data pipeline end-to-end
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        DATABASE_PATH: "./data/e2e_test.db"
        SYMBOLS: "AAPL"
        MIN_CONFIDENCE: "0.5"
      run: |
        PYTHONPATH=${{ github.workspace }} python main.py --test --symbols AAPL --min-confidence 0.5 || echo "E2E test completed with issues"

  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [test-matrix]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler

    - name: Run performance benchmarks
      env:
        TELEGRAM_BOT_TOKEN: "test_token"
        TELEGRAM_CHAT_ID: "test_chat_id"
      run: |
        PYTHONPATH=${{ github.workspace }} pytest tests/performance/ -v --benchmark-only --benchmark-json=benchmark.json

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.run_number }}
        path: benchmark.json
        retention-days: 30

  test-coverage-report:
    name: Coverage Report & Analysis
    runs-on: ubuntu-latest
    needs: [test-matrix]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install coverage[toml] coverage-badge

    - name: Run comprehensive coverage
      env:
        TELEGRAM_BOT_TOKEN: "test_token"
        TELEGRAM_CHAT_ID: "test_chat_id"
      run: |
        PYTHONPATH=${{ github.workspace }} coverage run -m pytest tests/
        coverage report --precision=2
        coverage html
        coverage xml
        coverage-badge -o coverage.svg

    - name: Comment coverage on PR
      if: github.event_name == 'pull_request'
      uses: py-cov-action/python-coverage-comment-action@v3
      with:
        GITHUB_TOKEN: ${{ github.token }}

    - name: Upload coverage artifacts
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report-${{ github.run_number }}
        path: |
          htmlcov/
          coverage.xml
          coverage.svg
        retention-days: 30