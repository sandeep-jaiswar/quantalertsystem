name: Quantitative Analysis & Alerts

on:
  schedule:
    # Run at market open (9:30 AM EST) on weekdays - Fixed timezone calculation
    - cron: '30 14 * * 1-5'  # 14:30 UTC = 9:30 AM EST (EST = UTC-5, EDT = UTC-4)
    # Run at market close (4:00 PM EST) on weekdays  
    - cron: '0 21 * * 1-5'   # 21:00 UTC = 4:00 PM EST
    # Run at midday (12:00 PM EST) on weekdays
    - cron: '0 17 * * 1-5'   # 17:00 UTC = 12:00 PM EST
  
  workflow_dispatch:  # Allow manual triggering with enhanced options
    inputs:
      symbols:
        description: 'Stock symbols to analyze (comma-separated)'
        required: false
        default: 'AAPL,GOOGL,MSFT,TSLA,NVDA,SPY,QQQ'
      min_confidence:
        description: 'Minimum confidence threshold (0.1-1.0)'
        required: false
        default: '0.6'
        type: string
      strategy_filter:
        description: 'Specific strategy to run (all/rsi/ma/bollinger/consensus)'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - rsi
          - ma
          - bollinger
          - consensus
      test_mode:
        description: 'Run in test mode (no real alerts)'
        required: false
        default: false
        type: boolean
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: false
        type: boolean

env:
  PYTHONPATH: ${{ github.workspace }}
  PYTHONUNBUFFERED: 1

jobs:
  pre-flight-checks:
    name: Pre-flight System Checks
    runs-on: ubuntu-latest
    outputs:
      market-open: ${{ steps.market-check.outputs.market-open }}
      config-valid: ${{ steps.config-check.outputs.config-valid }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .

    - name: Check market status
      id: market-check
      run: |
        # Check if market is open (US stock market hours)
        python -c "
        import datetime
        from datetime import timezone, timedelta
        
        # Get current time in EST
        est = timezone(timedelta(hours=-5))
        now = datetime.datetime.now(est)
        
        # Check if it's a weekday and during market hours (9:30 AM - 4:00 PM EST)
        is_weekday = now.weekday() < 5
        market_open_time = now.replace(hour=9, minute=30, second=0, microsecond=0)
        market_close_time = now.replace(hour=16, minute=0, second=0, microsecond=0)
        is_market_hours = market_open_time <= now <= market_close_time
        
        market_open = is_weekday and is_market_hours
        print(f'Market open: {market_open}')
        print(f'market-open={str(market_open).lower()}' + '::' + '$GITHUB_OUTPUT')
        "

    - name: Validate configuration
      id: config-check
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
      run: |
        python -c "
        from config.settings import get_settings
        try:
            settings = get_settings()
            print('‚úÖ Configuration validation successful')
            print('config-valid=true' + '::' + '$GITHUB_OUTPUT')
        except Exception as e:
            print(f'‚ùå Configuration validation failed: {e}')
            print('config-valid=false' + '::' + '$GITHUB_OUTPUT')
            exit(1)
        "

    - name: System health check
      run: |
        mkdir -p logs data
        python scripts/health_check.py --output logs/health-check.json

    - name: Upload pre-flight reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: pre-flight-reports-${{ github.run_number }}
        path: logs/
        retention-days: 7

  analyze:
    name: Quantitative Analysis Pipeline
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    if: needs.pre-flight-checks.outputs.config-valid == 'true'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies with retry
      run: |
        python -m pip install --upgrade pip
        for i in {1..3}; do
          pip install -r requirements.txt && break || sleep 10
        done
        pip install -e .

    - name: Create required directories
      run: |
        mkdir -p data logs reports
        chmod 755 data logs reports

    - name: Configure logging
      run: |
        python -c "
        import logging
        import os
        
        log_level = 'DEBUG' if '${{ github.event.inputs.debug_mode }}' == 'true' else 'INFO'
        
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/quant_analysis.log'),
                logging.StreamHandler()
            ]
        )
        
        logger = logging.getLogger('quantalertsystem')
        logger.info(f'Logging configured with level: {log_level}')
        "

    - name: System resource monitoring
      run: |
        python -c "
        import psutil
        import json
        
        system_info = {
            'cpu_count': psutil.cpu_count(),
            'memory_gb': round(psutil.virtual_memory().total / (1024**3), 2),
            'disk_gb': round(psutil.disk_usage('/').total / (1024**3), 2),
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent
        }
        
        with open('logs/system_resources.json', 'w') as f:
            json.dump(system_info, f, indent=2)
        
        print('System Resources:', json.dumps(system_info, indent=2))
        " || echo "Resource monitoring failed, continuing..."

    - name: Run system validation tests
      if: github.event.inputs.test_mode == 'true' || github.event_name == 'workflow_dispatch'
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        DATABASE_PATH: ./data/test_quant_alerts.db
        LOG_LEVEL: ${{ github.event.inputs.debug_mode == 'true' && 'DEBUG' || 'INFO' }}
      run: |
        echo "üß™ Running system validation tests..."
        python -m pytest tests/ -v -x --tb=short -k "not slow" || {
          echo "‚ùå System validation tests failed"
          exit 1
        }

    - name: Execute quantitative analysis pipeline
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        DATABASE_PATH: ./data/quant_alerts.db
        LOG_LEVEL: ${{ github.event.inputs.debug_mode == 'true' && 'DEBUG' || 'INFO' }}
        TEST_MODE: ${{ github.event.inputs.test_mode }}
      run: |
        set -e  # Exit on any error
        
        echo "üöÄ Starting quantitative analysis pipeline..."
        
        # Prepare analysis parameters
        SYMBOLS="${{ github.event.inputs.symbols || 'AAPL,GOOGL,MSFT,TSLA,NVDA,SPY,QQQ' }}"
        MIN_CONFIDENCE="${{ github.event.inputs.min_confidence || '0.6' }}"
        STRATEGY_FILTER="${{ github.event.inputs.strategy_filter || 'all' }}"
        
        echo "üìä Analysis Parameters:"
        echo "  Symbols: $SYMBOLS"
        echo "  Min Confidence: $MIN_CONFIDENCE"
        echo "  Strategy Filter: $STRATEGY_FILTER"
        echo "  Test Mode: $TEST_MODE"
        
        # Execute main analysis
        python -m quantalertsystem.main \
          --symbols "$SYMBOLS" \
          --min-confidence "$MIN_CONFIDENCE" \
          --strategy-filter "$STRATEGY_FILTER" \
          ${TEST_MODE:+--test-mode} \
          --timeout 1800 \
          2>&1 | tee logs/analysis_output.log

    - name: Post-analysis validation
      if: always()
      run: |
        echo "üîç Running post-analysis validation..."
        
        # Check if analysis completed successfully
        if [ -f "logs/analysis_output.log" ]; then
          if grep -q "Analysis completed successfully" logs/analysis_output.log; then
            echo "‚úÖ Analysis completed successfully"
            echo "ANALYSIS_STATUS=success" >> $GITHUB_ENV
          elif grep -q "Analysis completed with warnings" logs/analysis_output.log; then
            echo "‚ö†Ô∏è Analysis completed with warnings"
            echo "ANALYSIS_STATUS=warning" >> $GITHUB_ENV
          else
            echo "‚ùå Analysis may have failed"
            echo "ANALYSIS_STATUS=failed" >> $GITHUB_ENV
          fi
        else
          echo "‚ùå No analysis output found"
          echo "ANALYSIS_STATUS=failed" >> $GITHUB_ENV
        fi
        
        # Generate analysis summary
        python scripts/generate_analysis_summary.py \
          --input logs/ \
          --output logs/analysis_summary.json || echo "Summary generation failed"

    - name: Database health check
      if: always()
      run: |
        echo "üóÑÔ∏è Checking database health..."
        python -c "
        import sqlite3
        import os
        
        db_path = './data/quant_alerts.db'
        if os.path.exists(db_path):
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # Check tables exist
                cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")
                tables = cursor.fetchall()
                print(f'Database tables: {[t[0] for t in tables]}')
                
                # Check record counts
                for table in ['market_data', 'trading_signals', 'alerts']:
                    try:
                        cursor.execute(f'SELECT COUNT(*) FROM {table}')
                        count = cursor.fetchone()[0]
                        print(f'Records in {table}: {count}')
                    except:
                        print(f'Table {table} not found or inaccessible')
                
                conn.close()
                print('‚úÖ Database health check passed')
            except Exception as e:
                print(f'‚ùå Database health check failed: {e}')
        else:
            print('‚ö†Ô∏è Database not found (may be expected for test runs)')
        " || echo "Database check failed"

    - name: Upload analysis artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: analysis-results-${{ github.run_number }}
        path: |
          logs/
          data/
          reports/
        retention-days: 90

    - name: Cleanup sensitive data
      if: always()
      run: |
        # Remove any potential sensitive data from logs
        find logs/ -name "*.log" -exec sed -i 's/bot[0-9]\+:[A-Za-z0-9_-]\+/[BOT_TOKEN_REDACTED]/g' {} \;
        find logs/ -name "*.json" -exec sed -i 's/"bot_token": "[^"]*"/"bot_token": "[REDACTED]"/g' {} \;

  post-analysis:
    name: Post-Analysis Processing
    runs-on: ubuntu-latest
    needs: [analyze]
    if: always() && needs.analyze.result != 'cancelled'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install minimal dependencies
      run: |
        pip install requests pandas matplotlib

    - name: Download analysis artifacts
      uses: actions/download-artifact@v4
      with:
        name: analysis-results-${{ github.run_number }}

    - name: Generate performance metrics
      run: |
        python scripts/analyze_performance_metrics.py \
          --input logs/ \
          --output reports/performance_metrics.json || echo "Performance analysis failed"

    - name: Create analysis report
      run: |
        python scripts/create_analysis_report.py \
          --input . \
          --output reports/analysis_report.html || echo "Report generation failed"

    - name: Check for anomalies
      run: |
        python scripts/detect_anomalies.py \
          --input logs/ \
          --output reports/anomalies.json || echo "Anomaly detection failed"

    - name: Upload final reports
      uses: actions/upload-artifact@v4
      with:
        name: final-analysis-reports-${{ github.run_number }}
        path: reports/
        retention-days: 180

  cleanup:
    name: Cleanup & Maintenance
    runs-on: ubuntu-latest
    needs: [post-analysis]
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -e .

    - name: Database cleanup and optimization
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        DATABASE_PATH: ./data/quant_alerts.db
      run: |
        python -c "
        from quantalertsystem.data.storage import DataStorage
        import os
        
        if os.path.exists('./data/quant_alerts.db'):
            try:
                storage = DataStorage('./data/quant_alerts.db')
                storage.cleanup_old_data(days_to_keep=180)
                storage.optimize_database()
                storage.close()
                print('‚úÖ Database cleanup and optimization completed')
            except Exception as e:
                print(f'‚ùå Database cleanup failed: {e}')
        else:
            print('‚ÑπÔ∏è No database found for cleanup')
        " || echo "Cleanup failed but continuing"

    - name: Log analysis summary
      run: |
        echo "üìà Analysis Run Summary:"
        echo "  - Timestamp: $(date -u)"
        echo "  - Run Number: ${{ github.run_number }}"
        echo "  - Trigger: ${{ github.event_name }}"
        echo "  - Status: ${{ needs.analyze.result }}"